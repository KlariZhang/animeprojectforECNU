import requests
import json
import time
from datetime import datetime
from functools import reduce
from hashlib import md5
import urllib.parse

# --- 1. url ---
SEARCH_API_URL = "https://api.bilibili.com/x/web-interface/search/type"
EPISODE_LIST_API_URL = "https://api.bilibili.com/pgc/view/web/season"
COMMENT_API_URL = "https://api.bilibili.com/x/v2/reply/wbi/main" 

HEADERS =  {
    'Accept': '*/*',
    'Accept-Language': 'en-US,en;q=0.9,zh-CN;q=0.8,zh;q=0.7',
    'Connection': 'keep-alive',
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36',
    'Referer': 'https://www.bilibili.com/',
    "Cookie":""
}

# --- 2. WBIç­¾å ---
mixinKeyEncTab = [
    46, 47, 18, 2, 53, 8, 23, 32, 15, 50, 10, 31, 58, 3, 45, 35, 27, 43, 5, 49,
    33, 9, 42, 19, 29, 28, 14, 39, 12, 38, 41, 13, 37, 48, 7, 16, 24, 55, 40,
    61, 26, 17, 0, 1, 60, 51, 30, 4, 22, 25, 54, 21, 56, 59, 6, 63, 57, 62, 11,
    36, 20, 34, 44, 52
]

def getMixinKey(orig: str):
    return reduce(lambda s, i: s + orig[i], mixinKeyEncTab, '')[:32]

def encWbi(params: dict, img_key: str, sub_key: str):
    mixin_key = getMixinKey(img_key + sub_key)
    curr_time = round(time.time())
    params['wts'] = curr_time
    params = dict(sorted(params.items()))
    params = {
        k: ''.join(filter(lambda chr: chr not in "'!()*", str(v)))
        for k, v in params.items()
    }
    query = urllib.parse.urlencode(params)
    wbi_sign = md5((query + mixin_key).encode()).hexdigest()
    params['w_rid'] = wbi_sign
    return params

'è·å–æœ€æ–°çš„ img_key å’Œ sub_key,æ³¨æ„è¯¥å¯†é’¥æ¯æ—¥æ›´æ–°'
def getWbiKeys() -> tuple[str, str] | None:
             
    try:
        resp = requests.get('https://api.bilibili.com/x/web-interface/nav', headers=HEADERS)
        resp.raise_for_status()
        json_content = resp.json()
        img_url: str = json_content['data']['wbi_img']['img_url']
        sub_url: str = json_content['data']['wbi_img']['sub_url']
        img_key = img_url.rsplit('/', 1)[1].split('.')[0]
        sub_key = sub_url.rsplit('/', 1)[1].split('.')[0]
        return img_key, sub_key
    except Exception as e:
        print(f"[!] è·å–WBIå¯†é’¥å¤±è´¥: {e}")
        return None

# --- 3. æ•°æ®è·å– ---
'å›½åˆ›åç§°-> season_id'
def find_bangumi_season_id(keyword: str) -> dict | None:
    print(f"[*] æ­¥éª¤ 1: æ­£åœ¨ä¸ºå…³é”®è¯ '{keyword}' æœç´¢ç•ªå‰§...")
    params = {'search_type': 'media_bangumi', 'keyword': keyword}
    try:
        response = requests.get(SEARCH_API_URL, params=params, headers=HEADERS, timeout=10)
        response.raise_for_status()
        data = response.json()
        if data.get('code') == 0:
            results = data.get('data', {}).get('result')
            if not results: return None
            top_result = results[0]
            season_id = top_result.get('season_id')
            title = top_result.get('title', '').replace('<em class="keyword">', '').replace('</em>', '')
            if season_id:
                print(f"[âœ“] æˆåŠŸåŒ¹é…åˆ°ç•ªå‰§: '{title}', Season ID: {season_id}")
                return {'season_id': season_id, 'title': title}
    except Exception as e:
        print(f"[!] æ­¥éª¤1æ‰§è¡Œå¤±è´¥: {e}")
    return None

'season_id -> ep_id'
def get_all_episodes_info(season_id: int) -> list | None:
    print(f"\n[*] æ­¥éª¤ 2: æ­£åœ¨ç”¨ Season ID: {season_id} è·å–æ‰€æœ‰å‰§é›†çš„ä¿¡æ¯...")
    params = {'season_id': season_id}
    try:
        response = requests.get(EPISODE_LIST_API_URL, params=params, headers=HEADERS, timeout=10)
        response.raise_for_status()
        data = response.json()
        if data.get('code') == 0:
            episodes = data.get('result', {}).get('episodes')
            if not episodes: return None
            episode_info_list = []
            for ep in episodes:
                if ep.get('aid'):
                    episode_info_list.append({'title': ep.get('long_title'), 'aid': ep.get('aid')})
            print(f"[âœ“] æˆåŠŸè·å–åˆ° {len(episode_info_list)} é›†çš„æœ‰æ•ˆä¿¡æ¯.")
            return episode_info_list
    except Exception as e:
        print(f"[!] æ­¥éª¤2æ‰§è¡Œå¤±è´¥: {e}")
    return None

def fetch_comments_with_wbi(aid: int, episode_title: str, wbi_keys: tuple[str, str], scrape_all_pages: bool):
    """
    æ­¥éª¤3: æŠ“å–è¯„è®ºã€‚
    """
    all_comments_text = []
    total_comment_count = 0
    pagination_str = json.dumps({"offset":""})
    print(f"  -> å¼€å§‹å¤„ç† '{episode_title}' (aid: {aid}) çš„è¯„è®ºæŠ“å–...")

    while True:
        params = {'oid': aid, 'type': 1, 'mode': 3, 'pagination_str': pagination_str, 'plat': 1}
        signed_params = encWbi(params.copy(), img_key=wbi_keys[0], sub_key=wbi_keys[1])
        print(f"    - æ­£åœ¨è¯·æ±‚ (cursor: {params['pagination_str'][:40]}...)...")
        try:
            response = requests.get(COMMENT_API_URL, params=signed_params, headers=HEADERS, timeout=20)
            response.raise_for_status()
            data = response.json()
            if data.get('code') == 0:
                if data.get('data', {}).get('cursor', {}).get('all_count') is not None:
                    total_comment_count = data['data']['cursor']['all_count']
                
                replies = data.get('data', {}).get('replies')
                if replies:
                    for reply in replies:
                        all_comments_text.append(reply.get('content', {}).get('message'))
                    print(f"    [âœ“] æœ¬é¡µå¤„ç†å®Œæ¯•ï¼Œè·å¾— {len(replies)} æ¡è¯„è®ºã€‚")
                
                if not scrape_all_pages:
                    print(f"    [i] å·²è®¾ç½®ä¸ºåªæŠ“å–ç¬¬ä¸€é¡µï¼Œåœæ­¢ç¿»é¡µã€‚")
                    break

                if data.get('data', {}).get('cursor', {}).get('is_end'):
                    print(f"    [i] å·²åˆ°è¾¾æœ€åä¸€é¡µï¼Œåœæ­¢ç¿»é¡µã€‚")
                    break
                
                pagination_str = data['data']['cursor']['pagination_reply']['next_offset']
                time.sleep(2)
            else:
                print(f"    [!] APIè¿”å›é”™è¯¯: {data.get('message')}, åœæ­¢ç¿»é¡µã€‚")
                break
        except Exception as e:
            print(f"    [!] è¯·æ±‚è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}, åœæ­¢æŠ“å–æœ¬é›†ã€‚")
            break
            
    print(f"  [âœ“] '{episode_title}' è¯„è®ºæŠ“å–å®Œæˆã€‚å…± {len(all_comments_text)} æ¡(å·²åŠ è½½) / {total_comment_count} æ¡(æ€»è®¡)ã€‚")
    return total_comment_count, all_comments_text

def get_season_follower_count(season_id: int) -> int:
    """
    æ ¹æ®ç»™å®šçš„season_idï¼Œä»ç•ªå‰§è¯¦æƒ…APIä¸­è·å–å‡†ç¡®çš„è¿½ç•ªäººæ•°(series_follow)ã€‚

    :param season_id: ç•ªå‰§çš„Season IDã€‚
    :return: è¿½ç•ªäººæ•° (int)ã€‚å¦‚æœè·å–å¤±è´¥ï¼Œåˆ™è¿”å› -1ã€‚
    """
    params = {'season_id': season_id}
    
    try:
        response = requests.get(EPISODE_LIST_API_URL, params=params, headers=HEADERS, timeout=10)
        response.raise_for_status()
        data = response.json()
        
        if data.get('code') == 0:

            seasons_list = data.get('result', {}).get('seasons')
            if seasons_list:

                for season_item in seasons_list:
                    if season_item.get('season_id') == season_id:

                        stat_data = season_item.get('stat')
                        if stat_data:
 
                            followers = stat_data.get('series_follow')
                            if followers is not None:
                                print(f"[âœ“] æˆåŠŸè·å–è¿½ç•ªäººæ•° (series_follow): {followers}")
                                return followers
                print(f"[!] åœ¨seasonsåˆ—è¡¨ä¸­æœªæ‰¾åˆ°åŒ¹é…çš„ season_id: {season_id}ã€‚")
                return -1
            else:
                print("[!] APIå“åº”æˆåŠŸï¼Œä½†æœªæ‰¾åˆ° 'seasons' åˆ—è¡¨ã€‚")
                return -1
        else:
            print(f"[!] APIè¿”å›é”™è¯¯: {data.get('message')}")
            return -1
            
    except requests.exceptions.RequestException as e:
        print(f"[!] è¯·æ±‚è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return -1
    except Exception as e:
        print(f"[!] ç¨‹åºå‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
        return -1


# --- 4. ä¸»ç¨‹åº ---
if __name__ == "__main__":
    work_name = input("è¯·è¾“å…¥è¦çˆ¬å–çš„ç•ªå‰§åç§°: ")
    if not work_name:
        print("[!] è¾“å…¥ä¸ºç©ºï¼Œç¨‹åºé€€å‡ºã€‚")
    else:
        scrape_mode = input("è¯·é€‰æ‹©çˆ¬å–æ¨¡å¼ (1: åªçˆ¬å–ç¬¬ä¸€é¡µ, 2: çˆ¬å–æ‰€æœ‰è¯„è®º) [é»˜è®¤ä¸º 1]: ")
        scrape_all = (scrape_mode == '2')
            
        if scrape_all:
            print("[i] å·²é€‰æ‹©å®Œæ•´æ¨¡å¼ï¼Œå°†æŠ“å–æ‰€æœ‰ä¸€çº§è¯„è®ºã€‚")
        else:
            print("[i] å·²é€‰æ‹©é¦–é¡µæ¨¡å¼ï¼Œå°†åªæŠ“å–æ¯é›†çš„ç¬¬ä¸€é¡µè¯„è®ºã€‚")

    WORK_NAME = work_name 
    print("[*] æ­£åœ¨è·å–æœ€æ–°çš„WBIå¯†é’¥...")
    wbi_keys = getWbiKeys()
    if wbi_keys:
            print(f"[âœ“] WBIå¯†é’¥è·å–æˆåŠŸ!")
            bangumi_info = find_bangumi_season_id(work_name)
            if bangumi_info:
                all_episodes = get_all_episodes_info(bangumi_info['season_id'])
                follower_count = get_season_follower_count(bangumi_info['season_id'])
                print(follower_count)
                if all_episodes:
                    print(f"\n[+] æ‰¾åˆ° {len(all_episodes)} é›†ï¼Œå°†ä½¿ç”¨WBIç­¾åæ¨¡å¼å¼€å§‹éå†æŠ“å–...")
                    all_series_data = []

                    for i, episode in enumerate(all_episodes, 1):
                        print(f"\n--- å¤„ç†ç¬¬ {i}/{len(all_episodes)} é›†: {episode['title']} ---")
                        total_count, comments_text_list = fetch_comments_with_wbi(
                            aid=episode['aid'], 
                            episode_title=episode['title'],
                            wbi_keys=wbi_keys,
                            scrape_all_pages=scrape_all # å°†ç”¨æˆ·çš„é€‰æ‹©ä¼ é€’ç»™å‡½æ•°
                        )
                        all_series_data.append({
                            'episode_title': episode['title'],
                            'aid': episode['aid'],
                            'total_comment_count': total_count,
                            'comment_texts': comments_text_list
                        })
                        if i < len(all_episodes):
                            print("  [i] ä¼‘æ¯3ç§’ï¼Œå‡†å¤‡æŠ“å–ä¸‹ä¸€é›†...")
                            time.sleep(3)

                    file_name = f"bilibili_Comments_{bangumi_info['title']}.json"
                try:
                    with open(file_name, 'w', encoding='utf-8') as f:
                        json.dump(all_series_data, f, ensure_ascii=False, indent=4)
                        print(f"\n[ğŸ‰] å…¨éƒ¨ä»»åŠ¡æˆåŠŸï¼è¯„è®ºæ•°æ®å·²æ±‡æ€»ä¿å­˜è‡³æ–‡ä»¶: {file_name}")
                except Exception as e:
                            print(f"\n[!] æ–‡ä»¶ä¿å­˜å¤±è´¥: {e}")        
   
        